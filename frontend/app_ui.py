import streamlit as st
import pandas as pd
import datetime
import asyncio
import sys
import os
import json
import copy
from collections import Counter
from typing import List, Dict, Any, Union, Tuple

CURRENT_SCRIPT_DIR_UI = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT_UI = os.path.dirname(CURRENT_SCRIPT_DIR_UI)
if PROJECT_ROOT_UI not in sys.path:
    sys.path.insert(0, PROJECT_ROOT_UI)

try:
    import config as config_module
    from backend.app_logic import AnalysisService 
    from backend.vk_parser.parser import AsyncVKAPI 
    import aiohttp 
    if 'ui_module_loaded_print_once' not in st.session_state:
        print("UI: –û—Å–Ω–æ–≤–Ω—ã–µ –º–æ–¥—É–ª–∏ –±—ç–∫–µ–Ω–¥–∞ –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã.")
        st.session_state.ui_module_loaded_print_once = True

except ImportError as e:
    print(f"UI: –ù–µ —É–¥–∞–ª–æ—Å—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –æ—Å–Ω–æ–≤–Ω—ã–µ –±—ç–∫–µ–Ω–¥-–º–æ–¥—É–ª–∏: {e}. –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –Ω–µ –º–æ–∂–µ—Ç –∑–∞–ø—É—Å—Ç–∏—Ç—å—Å—è.")
    sys.exit(1) 

def load_tesa_label_map_for_ui(config_ref: Any) -> Dict[int, str]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å –º–µ—Ç–æ–∫ TESA –∏–∑ JSON-—Ñ–∞–π–ª–∞,
    –ø—É—Ç—å –∫ –∫–æ—Ç–æ—Ä–æ–º—É —É–∫–∞–∑–∞–Ω –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω–æ–º –º–æ–¥—É–ª–µ.

    Args:
        config_ref (Any): –°—Å—ã–ª–∫–∞ –Ω–∞ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–æ–¥—É–ª—å config.

    Returns:
        Dict[int, str]: –°–ª–æ–≤–∞—Ä—å —Å –∫–∞—Ä—Ç–æ–π –º–µ—Ç–æ–∫ TESA.
    """
    if not hasattr(config_ref, 'TESA_LABEL_MAP_PATH'):
        print("UI : TESA_LABEL_MAP_PATH –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ config_module_ref, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∑–∞–≥–ª—É—à–∫–∞ –¥–ª—è –º–µ—Ç–æ–∫.")
        return {0: "POS", 1: "NEG", 2: "NEU"}
    tesa_label_map_path = config_ref.TESA_LABEL_MAP_PATH
    default_map = {0: "POS", 1: "NEG", 2: "NEU"}
    try:
        with open(tesa_label_map_path, 'r', encoding='utf-8') as f:
            tesa_maps_json = json.load(f)
            id2label = {int(k): v for k, v in tesa_maps_json.get('id2label', {}).items()}
            if not id2label:
                print(f"UI: –°–ª–æ–≤–∞—Ä—å 'id2label' –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –ø—É—Å—Ç –≤ —Ñ–∞–π–ª–µ {tesa_label_map_path}. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∑–∞–≥–ª—É—à–∫–∞.")
                return default_map
            return id2label
    except FileNotFoundError:
        print(f"UI: –§–∞–π–ª —Å–ª–æ–≤–∞—Ä—è –º–µ—Ç–æ–∫ TESA –Ω–µ –Ω–∞–π–¥–µ–Ω –ø–æ –ø—É—Ç–∏: {tesa_label_map_path}. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∑–∞–≥–ª—É—à–∫–∞.")
        return default_map
    except Exception as e:
        print(f"UI: –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ/—á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞ —Å–ª–æ–≤–∞—Ä—è –º–µ—Ç–æ–∫ TESA {tesa_label_map_path}: {e}. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∑–∞–≥–ª—É—à–∫–∞.")
        return default_map

def initialize_app_state_and_services():
    """
    –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–µ—Å—Å–∏–∏ Streamlit –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–º–∏ 
    –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏ —Å–æ–∑–¥–∞–µ—Ç —ç–∫–∑–µ–º–ø–ª—è—Ä `AnalysisService`.
    """
    if 'app_initialized' not in st.session_state:
        defaults = {
            'tesa_id2label': load_tesa_label_map_for_ui(config_module),
            'current_group_name': "–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞",
            'last_group_input': getattr(config_module, 'DEFAULT_GROUP_IDENTIFIERS', [""])[0],
            'last_processed_group_input': "", 
            'last_processed_group_name': "–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞",
            'last_processed_start_date': None, 
            'last_processed_end_date': None, 
            'ui_start_date': max(datetime.date.today() - datetime.timedelta(days=6), datetime.date.today() - datetime.timedelta(days=365*5)),
            'ui_end_date': datetime.date.today(),
            'initial_summary': None,
            'initial_detailed_mentions': None,
            'current_summary_display': None,
            'current_detailed_mentions_display': None,
            'analysis_triggered_and_pending': False,
            'multiselect_key_counter': 0,
            'selected_entities_for_merge': [], 
            'person_selected_for_details_dropdown': None,
            'analysis_service_instance': None,
            'app_initialization_error': None}
        for key, value in defaults.items():
            if key not in st.session_state:
                st.session_state[key] = value        
        try:
            st.session_state.analysis_service_instance = AnalysisService()
            print("UI INFO: AnalysisService —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")
        except Exception as e_init_service:
            error_msg = f"UI –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å AnalysisService: {e_init_service}. –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª –∞–Ω–∞–ª–∏–∑–∞ –±—É–¥–µ—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω."
            print(error_msg)
            st.session_state.app_initialization_error = error_msg
        st.session_state.app_initialized = True

initialize_app_state_and_services()

# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è (–º–æ–∂–Ω–æ —Ä–∞–∑–º–µ—Å—Ç–∏—Ç—å –≤ –Ω–∞—á–∞–ª–µ app_ui.py)
def clean_vk_identifier_for_api(input_str: str) -> str:
    """
    –û—á–∏—â–∞–µ—Ç –≤–≤–µ–¥–µ–Ω–Ω—É—é —Å—Ç—Ä–æ–∫—É –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è ID –∏–ª–∏ –∫–æ—Ä–æ—Ç–∫–æ–≥–æ –∏–º–µ–Ω–∏ (screen_name),
    –ø—Ä–∏–≥–æ–¥–Ω–æ–≥–æ –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –≤ –º–µ—Ç–æ–¥—ã VK API, –æ–∂–∏–¥–∞—é—â–∏–µ group_id –∏–ª–∏ user_id.
    """
    if not input_str:
        return ""
    cleaned_id = input_str.strip()
    if cleaned_id.startswith("http://"):
        cleaned_id = cleaned_id[7:]
    elif cleaned_id.startswith("https://"):
        cleaned_id = cleaned_id[8:]
    if cleaned_id.startswith("vk.com/"):
        cleaned_id = cleaned_id[7:]
    elif cleaned_id.startswith("m.vk.com/"): 
        cleaned_id = cleaned_id[9:]
    if "/" in cleaned_id:
        cleaned_id = cleaned_id.split("/")[0]
    if "?" in cleaned_id:
        cleaned_id = cleaned_id.split("?")[0]
    if "#" in cleaned_id:
        cleaned_id = cleaned_id.split("#")[0]
    _identifier = input_str.strip()
    if _identifier.startswith("https://"): _identifier = _identifier[8:]
    elif _identifier.startswith("http://"): _identifier = _identifier[7:]
    if _identifier.startswith("vk.com/"): _identifier = _identifier[7:]
    elif _identifier.startswith("m.vk.com/"): _identifier = _identifier[9:]
    if "/" in _identifier: _identifier = _identifier.split("/")[0]
    if "?" in _identifier: _identifier = _identifier.split("?")[0]
    if "#" in _identifier: _identifier = _identifier.split("#")[0]
    if not _identifier:
        print(f"UI WARN: –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∏–∑ '{input_str}'")
        return ""
    return _identifier

async def fetch_display_group_name_ui_wrapper(group_id_or_url_ui: str):
    """
    –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –ø–æ–ª—É—á–∞–µ—Ç –∏ –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –∏–º—è –≥—Ä—É–ø–ø—ã –í–ö–æ–Ω—Ç–∞–∫—Ç–µ –ø–æ –µ–µ ID –∏–ª–∏ URL.

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç AsyncVKAPI –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ –∫ VK API. –†–µ–∑—É–ª—å—Ç–∞—Ç (–∏–º—è –≥—Ä—É–ø–ø—ã
    –∏–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ) —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –≤ st.session_state.current_group_name.

    Args:
        group_id_or_url_ui (str): –°—Ç—Ä–æ–∫–∞, —Å–æ–¥–µ—Ä–∂–∞—â–∞—è ID, –∫–æ—Ä–æ—Ç–∫–æ–µ –∏–º—è –∏–ª–∏ URL –≥—Ä—É–ø–ø—ã VK.
    """
    if not group_id_or_url_ui:
        st.session_state.current_group_name = "ID –≥—Ä—É–ø–ø—ã –Ω–µ —É–∫–∞–∑–∞–Ω"
        return
    if not hasattr(config_module, 'VK_SERVICE_TOKEN') or not config_module.VK_SERVICE_TOKEN or \
       not hasattr(config_module, 'VK_API_BASE_URL') or not config_module.VK_API_BASE_URL or \
       not hasattr(config_module, 'VK_API_VERSION'):
        st.session_state.current_group_name = "–û—à–∏–±–∫–∞: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è VK API –Ω–µ–ø–æ–ª–Ω–∞—è –≤ config.py."
        print("UI: VK_SERVICE_TOKEN, VK_API_BASE_URL –∏–ª–∏ VK_API_VERSION –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ config_module.")
        return
    
    identifier = clean_vk_identifier_for_api(group_id_or_url_ui)
    
    try:
        async with aiohttp.ClientSession() as session: 
            vk_api_client_ui = AsyncVKAPI(session=session, token=config_module.VK_SERVICE_TOKEN,
                                          api_version=config_module.VK_API_VERSION, api_base_url=config_module.VK_API_BASE_URL)
            
            group_data_list = await vk_api_client_ui.groups_getById(group_id=identifier, fields="name,screen_name")
            
            if group_data_list and isinstance(group_data_list, list) and group_data_list:
                group_info = group_data_list[0]
                st.session_state.current_group_name = group_info.get("name", f"–ì—Ä—É–ø–ø–∞ '{identifier}'")
                print(f"UI INFO: –ò–º—è –≥—Ä—É–ø–ø—ã '{st.session_state.current_group_name}' –¥–ª—è ID/–¥–æ–º–µ–Ω–∞ '{identifier}' –ø–æ–ª—É—á–µ–Ω–æ.")
            else:
                st.session_state.current_group_name = f"–ì—Ä—É–ø–ø–∞ '{identifier}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –∏–ª–∏ API –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç."
                print(f"UI WARNING: –ì—Ä—É–ø–ø–∞ '{identifier}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –∏–ª–∏ API –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è groups.getById.")
    except Exception as e:
        st.session_state.current_group_name = f"–û—à–∏–±–∫–∞ ({type(e).__name__}) –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –∏–º–µ–Ω–∏ '{identifier}'"
        print(f"UI ERROR –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –∏–º–µ–Ω–∏ –≥—Ä—É–ø–ø—ã '{identifier}': {e}")        

def load_detailed_results_from_file(filepath: str) -> Tuple[List[Dict[str, Any]], List[str]]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ 
    –∏–∑ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ JSONL —Ñ–∞–π–ª–∞.

    Args:
        filepath (str): –ü—É—Ç—å –∫ JSONL —Ñ–∞–π–ª—É —Å –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏.

    Returns:
        Tuple[List[Dict[str, Any]], List[str]]:
            - detailed_mentions: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π, –≥–¥–µ –∫–∞–∂–¥—ã–π —Å–ª–æ–≤–∞—Ä—å - –æ–¥–Ω–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ.
            - processed_group_names: –°–ø–∏—Å–æ–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∏–º–µ–Ω –≥—Ä—É–ø–ø, –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –≤ –¥–∞–Ω–Ω—ã—Ö.
            –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Å—Ç—ã–µ —Å–ø–∏—Å–∫–∏ –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –∏–ª–∏ –µ—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω.
    """
    detailed_mentions = []
    processed_group_names = set()
    if not filepath or not os.path.exists(filepath):
        return detailed_mentions, list(processed_group_names)
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            for line_number, line in enumerate(f):
                try:
                    mention_data = json.loads(line)
                    detailed_mentions.append(mention_data)
                    if mention_data.get("group_name"):
                        processed_group_names.add(mention_data["group_name"])
                except json.JSONDecodeError:
                    print(f"UI: –û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è JSON –≤ —Ñ–∞–π–ª–µ –¥–µ—Ç–∞–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, —Å—Ç—Ä–æ–∫–∞ {line_number+1}: {line.strip()}")
    except Exception as e:
        print(f"UI: –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ –¥–µ—Ç–∞–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ {filepath}: {e}")
    return detailed_mentions, list(processed_group_names)

# --- –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ ---
def render_sidebar():
    """
    –û—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ—Ç –±–æ–∫–æ–≤—É—é –ø–∞–Ω–µ–ª—å —Å —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è
    –¥–ª—è –≤–≤–æ–¥–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∞–Ω–∞–ª–∏–∑–∞.
    –¢–∞–∫–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–Ω–æ–ø–∫—É –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∞–Ω–∞–ª–∏–∑–∞.
    """
    with st.sidebar:
        st.markdown("# **–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∞–Ω–∞–ª–∏–∑–∞**") 
        default_group_id_ui = (hasattr(config_module, 'DEFAULT_GROUP_IDENTIFIERS') and 
                               len(config_module.DEFAULT_GROUP_IDENTIFIERS) > 0 and 
                               config_module.DEFAULT_GROUP_IDENTIFIERS[0]) or "zlo43"        
        st.markdown("## **–¶–µ–ª–µ–≤–∞—è –≥—Ä—É–ø–ø–∞ –í–ö–æ–Ω—Ç–∞–∫—Ç–µ**") 
        group_url_or_id_input_val = st.text_input(
            "–°—Å—ã–ª–∫–∞ –∏–ª–∏ –∫–æ—Ä–æ—Ç–∫–æ–µ –∏–º—è –≥—Ä—É–ø–ø—ã:", 
            value=st.session_state.last_group_input or default_group_id_ui,
            help="–ù–∞–ø—Ä–∏–º–µ—Ä, 'zlo43' –∏–ª–∏ 'lentach'",
            key="group_input_widget_sidebar_key_v5" ) 
        if group_url_or_id_input_val != st.session_state.last_group_input:
            st.session_state.last_group_input = group_url_or_id_input_val        
        if st.button("–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∏–º—è –≥—Ä—É–ø–ø—ã", key="check_group_name_button_sidebar_key_v5"):
            if st.session_state.last_group_input:
                asyncio.run(fetch_display_group_name_ui_wrapper(st.session_state.last_group_input))
                st.rerun()
        if st.session_state.current_group_name and st.session_state.current_group_name != "–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞":
            st.caption(f"–í—ã–±—Ä–∞–Ω–Ω–∞—è –≥—Ä—É–ø–ø–∞: **{st.session_state.current_group_name}**")
        elif st.session_state.last_group_input : 
            st.caption(f"–î–ª—è –≥—Ä—É–ø–ø—ã '{st.session_state.last_group_input}' –∏–º—è –Ω–µ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ.")
        else:
            st.caption("–í–≤–µ–¥–∏—Ç–µ ID –≥—Ä—É–ø–ø—ã –∏ –Ω–∞–∂–º–∏—Ç–µ '–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∏–º—è –≥—Ä—É–ø–ø—ã'.")
        st.markdown("---")
        st.markdown("## **–ü–µ—Ä–∏–æ–¥ –∞–Ω–∞–ª–∏–∑–∞**")
        today = datetime.date.today()        
        five_years_ago = today - datetime.timedelta(days=365 * 5)         
        start_date_selected = st.date_input( 
            "–ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞:", value=st.session_state.ui_start_date,
            min_value=five_years_ago, max_value=today, key="start_date_widget_sidebar_key_v5")
        if start_date_selected != st.session_state.ui_start_date:
            st.session_state.ui_start_date = start_date_selected
            if st.session_state.ui_end_date < st.session_state.ui_start_date:
                st.session_state.ui_end_date = st.session_state.ui_start_date
            if (st.session_state.ui_end_date - st.session_state.ui_start_date).days > 365: 
                st.session_state.ui_end_date = st.session_state.ui_start_date + datetime.timedelta(days=365)
                if st.session_state.ui_end_date > today: st.session_state.ui_end_date = today
            st.rerun()
        actual_max_end_date_for_widget = min(today, st.session_state.ui_start_date + datetime.timedelta(days=365))
        end_date_selected = st.date_input( 
            "–ö–æ–Ω–µ—á–Ω–∞—è –¥–∞—Ç–∞:", value=st.session_state.ui_end_date,
            min_value=st.session_state.ui_start_date, max_value=actual_max_end_date_for_widget, key="end_date_widget_sidebar_key_v5")
        if end_date_selected != st.session_state.ui_end_date:
            st.session_state.ui_end_date = end_date_selected
            st.rerun()        
        period_is_invalid = (st.session_state.ui_end_date - st.session_state.ui_start_date).days > 365 or \
                            st.session_state.ui_start_date > st.session_state.ui_end_date
        if (st.session_state.ui_end_date - st.session_state.ui_start_date).days > 365:
            st.warning("–ü–µ—Ä–∏–æ–¥ –Ω–µ –¥–æ–ª–∂–µ–Ω –ø—Ä–µ–≤—ã—à–∞—Ç—å 1 –≥–æ–¥.")
        if st.session_state.ui_start_date > st.session_state.ui_end_date:
            st.error("–ù–∞—á–∞–ª—å–Ω–∞—è –¥–∞—Ç–∞ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–∑–∂–µ –∫–æ–Ω–µ—á–Ω–æ–π.")        
        analysis_possible = st.session_state.analysis_service_instance is not None and \
                            st.session_state.last_group_input and \
                            st.session_state.current_group_name != "–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞" and \
                            "–ù–µ —É–¥–∞–ª–æ—Å—å" not in st.session_state.current_group_name and \
                            "–û—à–∏–±–∫–∞" not in st.session_state.current_group_name
        if st.button("–ù–∞—á–∞—Ç—å –∞–Ω–∞–ª–∏–∑", type="primary", disabled=period_is_invalid or not analysis_possible, key="start_analysis_button_sidebar_key_v5"):
            if not analysis_possible:
                st.warning("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π ID –≥—Ä—É–ø–ø—ã, –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –∏–º—è –∏ —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –Ω–µ—Ç –æ—à–∏–±–æ–∫ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏.")
            else:
                st.session_state.current_summary_display = None
                st.session_state.current_detailed_mentions_display = None
                st.session_state.initial_summary = None
                st.session_state.analysis_triggered_and_pending = True
                st.session_state.selected_entities_for_merge = []
                st.session_state.multiselect_key_counter += 1
                st.session_state.person_selected_for_details_dropdown = None
                raw_group_input_from_state = st.session_state.last_group_input 
                cleaned_group_id_for_processing = clean_vk_identifier_for_api(raw_group_input_from_state)
                st.session_state.last_processed_group_input = cleaned_group_id_for_processing
                st.session_state.last_processed_group_name = st.session_state.current_group_name
                st.session_state.last_processed_start_date = st.session_state.ui_start_date
                st.session_state.last_processed_end_date = st.session_state.ui_end_date
                st.rerun() 
                
def render_report_header():
    """
    –û—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ—Ç –∑–∞–≥–æ–ª–æ–≤–æ–∫ –æ—Ç—á–µ—Ç–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏ UI,
    –µ—Å–ª–∏ –∞–Ω–∞–ª–∏–∑ –±—ã–ª –ø—Ä–æ–≤–µ–¥–µ–Ω –∏ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è.
    –í–∫–ª—é—á–∞–µ—Ç –∏–º—è –≥—Ä—É–ø–ø—ã, –ø–µ—Ä–∏–æ–¥ –∞–Ω–∞–ª–∏–∑–∞ –∏ –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø–µ—Ä—Å–æ–Ω.
    """
    if st.session_state.last_processed_group_name != "–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞" and st.session_state.current_summary_display is not None:
        st.header(f"–û—Ç—á–µ—Ç –ø–æ –≥—Ä—É–ø–ø–µ: {st.session_state.last_processed_group_name}")
        if st.session_state.last_processed_start_date and st.session_state.last_processed_end_date:
            st.subheader(f"–ü–µ—Ä–∏–æ–¥: {st.session_state.last_processed_start_date.strftime('%d.%m.%Y')} - {st.session_state.last_processed_end_date.strftime('%d.%m.%Y')}")
        total_unique_persons = len(st.session_state.current_summary_display.keys())
        st.success(f"### **–ù–∞–π–¥–µ–Ω–æ –º–Ω–µ–Ω–∏–π –æ {total_unique_persons} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–µ—Ä—Å–æ–Ω–∞—Ö**") 
        st.markdown("---")

def render_top10_summary(summary_data: Dict[str, Any], tesa_labels: Dict[int, str]):
    """
    –û—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ—Ç —Å–µ–∫—Ü–∏—é —Å —Ç–æ–ø —É–ø–æ–º–∏–Ω–∞–µ–º—ã–º–∏ –ø–µ—Ä—Å–æ–Ω–∞–º–∏.

    Args:
        summary_data (Dict[str, Any]): –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∞–Ω–∞–ª–∏–∑–∞ 
                                       (–∫–ª—é—á 'summary_by_entity_date' –∏–∑ –æ—Ç–≤–µ—Ç–∞ —Å–µ—Ä–≤–∏—Å–∞).
        tesa_labels (Dict[int, str]): –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è ID –º–µ—Ç–æ–∫ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ —Å –∏—Ö –∏–º–µ–Ω–∞–º–∏.
    """
    if not summary_data: st.write("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ç–æ–ø–∞."); return
    st.subheader("–¢–æ–ø-10 —É–ø–æ–º–∏–Ω–∞–µ–º—ã—Ö –ø–µ—Ä—Å–æ–Ω –∏ –∏—Ö —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å")
    entity_total_counts = Counter()
    person_sentiment_overall = {}
    pos_label = tesa_labels.get(0, "POS"); neg_label = tesa_labels.get(1, "NEG"); neu_label = tesa_labels.get(2, "NEU")
    for person, date_data in summary_data.items():
        pos, neg, neu = 0,0,0
        for _, counts in date_data.items(): pos += counts.get(pos_label,0); neg += counts.get(neg_label,0); neu += counts.get(neu_label,0)
        entity_total_counts[person] = pos + neg + neu
        person_sentiment_overall[person] = {pos_label:pos, neg_label:neg, neu_label:neu}    
    top_n = 10 
    if not entity_total_counts: st.write("–î–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–æ–ø–∞ –ø–µ—Ä—Å–æ–Ω –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç."); return
    most_common_persons = entity_total_counts.most_common(top_n)
    df_top_persons_data = [{"–ü–µ—Ä—Å–æ–Ω–∞": p, "–í—Å–µ–≥–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π": tc,
                            "–ü–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö": person_sentiment_overall.get(p,{}).get(pos_label,0),
                            "–ù–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö": person_sentiment_overall.get(p,{}).get(neg_label,0),
                            "–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã—Ö": person_sentiment_overall.get(p,{}).get(neu_label,0)} 
                           for p, tc in most_common_persons]
    df_top = pd.DataFrame(df_top_persons_data).set_index("–ü–µ—Ä—Å–æ–Ω–∞")
    if not df_top.empty:
        st.dataframe(df_top, use_container_width=True)
        st.markdown("#### –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π (–¢–æ–ø-10)")
        st.bar_chart(df_top[["–í—Å–µ–≥–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π"]], height=300)
        st.markdown("#### –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–µ–π (–¢–æ–ø-10)")
        st.bar_chart(df_top[["–ü–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö", "–ù–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö", "–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã—Ö"]], height=400)
_multiselect_key_for_callback = ""

def update_multiselect_selection_callback():
    """
    –ö–æ–ª–±—ç–∫-—Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –≤–∏–¥–∂–µ—Ç–∞ st.multiselect.
    –û–±–Ω–æ–≤–ª—è–µ—Ç st.session_state.selected_entities_for_merge —Ç–µ–∫—É—â–∏–º –≤—ã–±–æ—Ä–æ–º
    –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ –≤–∏–¥–∂–µ—Ç–∞ st.multiselect.
    """
    if _multiselect_key_for_callback in st.session_state:
        st.session_state.selected_entities_for_merge = st.session_state[_multiselect_key_for_callback]
        
def update_selectbox_details_callback(selectbox_key: str):
    """
    –ö–æ–ª–±—ç–∫-—Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –≤–∏–¥–∂–µ—Ç–∞ st.selectbox (–≤—ã–±–æ—Ä –ø–µ—Ä—Å–æ–Ω—ã –¥–ª—è –¥–µ—Ç–∞–ª–µ–π).
    –û–±–Ω–æ–≤–ª—è–µ—Ç st.session_state.person_selected_for_details_dropdown
    —Ç–µ–∫—É—â–∏–º –≤—ã–±–æ—Ä–æ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

    Args:
        selectbox_key (str): –ö–ª—é—á –≤–∏–¥–∂–µ—Ç–∞ `st.selectbox`, –∑–Ω–∞—á–µ–Ω–∏–µ –∫–æ—Ç–æ—Ä–æ–≥–æ –Ω—É–∂–Ω–æ –ø—Ä–æ—á–∏—Ç–∞—Ç—å.
    """
    if selectbox_key in st.session_state:
        selected_value = st.session_state[selectbox_key]
        st.session_state.person_selected_for_details_dropdown = selected_value if selected_value else None 

def render_main_report_table_and_merge(summary_data: Dict[str, Any], 
                                       detailed_mentions_data: List[Dict[str, Any]], 
                                       tesa_labels: Dict[int, str], 
                                       service_instance: Union[AnalysisService, None]):
    """
    –û—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ—Ç —Å–≤–æ–¥–Ω—É—é —Ç–∞–±–ª–∏—Ü—É —Å–æ –≤—Å–µ–º–∏ –Ω–∞–π–¥–µ–Ω–Ω—ã–º–∏ –ø–µ—Ä—Å–æ–Ω–∞–º–∏
    –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —ç–ª–µ–º–µ–Ω—Ç—ã —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–ª—è –∏—Ö –ø–æ–∏—Å–∫–∞ –∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è.

    Args:
        summary_data (Dict[str, Any]): –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∞–Ω–∞–ª–∏–∑–∞.
        detailed_mentions_data (List[Dict[str, Any]]): –°–ø–∏—Å–æ–∫ –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —É–ø–æ–º–∏–Ω–∞–Ω–∏–π.
        tesa_labels (Dict[int, str]): –°–ª–æ–≤–∞—Ä—å –º–µ—Ç–æ–∫ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏.
        service_instance (Union[AnalysisService, None]): –≠–∫–∑–µ–º–ø–ª—è—Ä —Å–µ—Ä–≤–∏—Å–∞ –∞–Ω–∞–ª–∏–∑–∞
                                                         –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –æ–ø–µ—Ä–∞—Ü–∏–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è.
                                                         –ï—Å–ª–∏ None, —Ñ—É–Ω–∫—Ü–∏—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –±—É–¥–µ—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞.
    """
    global _multiselect_key_for_callback 
    if not summary_data: st.write("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞."); return    
    st.markdown("---"); st.subheader("üîé –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø–µ—Ä—Å–æ–Ω")
    search_query = st.text_input("–ü–æ–∏—Å–∫ –ø–æ –ø–µ—Ä—Å–æ–Ω–∞–º –≤ —Ç–∞–±–ª–∏—Ü–µ:", key="entity_search_main_table_key_v5")
    summary_table_data_for_df = []
    pos_label = tesa_labels.get(0, "POS"); neg_label = tesa_labels.get(1, "NEG"); neu_label = tesa_labels.get(2, "NEU")
    for person, date_data_map in summary_data.items():
        total_mentions, pos, neg, neu = 0,0,0,0
        for counts in date_data_map.values():
            p_c = counts.get(pos_label,0); n_c = counts.get(neg_label,0); u_c = counts.get(neu_label,0)
            pos+=p_c; neg+=n_c; neu+=u_c; total_mentions+=(p_c+n_c+u_c)
        summary_table_data_for_df.append({"–ü–µ—Ä—Å–æ–Ω–∞":person, "–í—Å–µ–≥–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π":total_mentions, "–ü–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö":pos, "–ù–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö":neg, "–ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã—Ö":neu})    
    if not summary_table_data_for_df: st.write("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã."); return
    df_full = pd.DataFrame(summary_table_data_for_df).sort_values(by="–í—Å–µ–≥–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π", ascending=False).reset_index(drop=True)
    df_display = df_full[df_full["–ü–µ—Ä—Å–æ–Ω–∞"].str.contains(search_query, case=False, na=False)] if search_query else df_full
    st.dataframe(df_display.set_index("–ü–µ—Ä—Å–æ–Ω–∞"), height=400, use_container_width=True)
    st.markdown("---"); st.markdown("### –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –ø–µ—Ä—Å–æ–Ω")
    options = df_display["–ü–µ—Ä—Å–æ–Ω–∞"].tolist()    
    _multiselect_key_for_callback = f"entities_multiselect_key_v5_{st.session_state.multiselect_key_counter}" 
    valid_current_selection = [s for s in st.session_state.selected_entities_for_merge if s in options]     
    st.multiselect("–í—ã–±–µ—Ä–∏—Ç–µ –ø–µ—Ä—Å–æ–Ω—ã –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è (>1):", 
                   options=options, default=valid_current_selection, 
                   key=_multiselect_key_for_callback, on_change=update_multiselect_selection_callback)
    if st.session_state.initial_summary is not None:
        if st.button("–°–±—Ä–æ—Å–∏—Ç—å –≤—Å–µ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è", key="reset_btn_v5_global"):
            st.session_state.current_summary_display = copy.deepcopy(st.session_state.initial_summary)
            st.session_state.current_detailed_mentions_display = copy.deepcopy(st.session_state.initial_detailed_mentions or [])
            st.session_state.selected_entities_for_merge = [] 
            st.session_state.multiselect_key_counter +=1     
            if st.session_state.person_selected_for_details_dropdown and \
               st.session_state.person_selected_for_details_dropdown not in st.session_state.current_summary_display:
                st.session_state.person_selected_for_details_dropdown = None
            st.info("–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è —Å–±—Ä–æ—à–µ–Ω—ã."); st.rerun()

    if len(st.session_state.selected_entities_for_merge) > 1:
        canon_name = st.text_input("–ö–∞–Ω–æ–Ω–∏—á–µ—Å–∫–æ–µ –∏–º—è:", 
                                   value=max(st.session_state.selected_entities_for_merge, key=len, default=""), 
                                   key="canon_name_input_v5") 
        if st.button("–û–±—ä–µ–¥–∏–Ω–∏—Ç—å –≤—ã–±—Ä–∞–Ω–Ω—ã–µ", key="merge_btn_v5", type="primary"):
            if canon_name.strip() and service_instance:
                new_sum, new_det = service_instance.reaggregate_with_aliases(
                    st.session_state.current_summary_display,
                    st.session_state.current_detailed_mentions_display or [],
                    st.session_state.selected_entities_for_merge, canon_name.strip())
                st.session_state.current_summary_display = new_sum
                st.session_state.current_detailed_mentions_display = new_det
                st.session_state.selected_entities_for_merge = [] 
                st.session_state.multiselect_key_counter +=1 
                if st.session_state.person_selected_for_details_dropdown and \
                   (st.session_state.person_selected_for_details_dropdown in st.session_state.selected_entities_for_merge or \
                    st.session_state.person_selected_for_details_dropdown not in st.session_state.current_summary_display):
                     st.session_state.person_selected_for_details_dropdown = None                
                st.rerun()
            elif not service_instance:
                 st.error("–°–µ—Ä–≤–∏—Å –∞–Ω–∞–ª–∏–∑–∞ –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è.")
            else: st.warning("–£–∫–∞–∂–∏—Ç–µ –∫–∞–Ω–æ–Ω–∏—á–µ—Å–∫–æ–µ –∏–º—è.")

def render_person_details_expander(summary_data: Dict[str, Any], 
                                   detailed_mentions_data: List[Dict[str, Any]], 
                                   tesa_labels: Dict[int, str]):
    """
    –û—Ç—Ä–∏—Å–æ–≤—ã–≤–∞–µ—Ç —Å–µ–∫—Ü–∏—é –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –ø–µ—Ä—Å–æ–Ω–µ.

    Args:
        summary_data (Dict[str, Any]): –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∞–Ω–∞–ª–∏–∑–∞.
        detailed_mentions_data (List[Dict[str, Any]]): –°–ø–∏—Å–æ–∫ –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —É–ø–æ–º–∏–Ω–∞–Ω–∏–π.
        tesa_labels (Dict[int, str]): –°–ª–æ–≤–∞—Ä—å –º–µ—Ç–æ–∫ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏.
    """
    if not summary_data or len(summary_data) == 0: return 
    st.markdown("---"); st.subheader("üìú –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–µ—Ä—Å–æ–Ω—ã")        
    person_options = [""] + sorted(list(summary_data.keys())) 
    selectbox_key = f"person_details_selectbox_v5_{st.session_state.multiselect_key_counter}" 
    current_person_for_details = st.session_state.person_selected_for_details_dropdown
    if current_person_for_details not in person_options:
        current_person_for_details = "" 
        if st.session_state.person_selected_for_details_dropdown is not None: 
            st.session_state.person_selected_for_details_dropdown = None 
    st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –ø–µ—Ä—Å–æ–Ω—É –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –¥–µ—Ç–∞–ª–µ–π:", 
                 options=person_options, 
                 index=person_options.index(current_person_for_details) if current_person_for_details in person_options else 0,
                 key=selectbox_key,
                 on_change=update_selectbox_details_callback,
                 args=(selectbox_key,))     
    if st.session_state.person_selected_for_details_dropdown:
        person_to_show = st.session_state.person_selected_for_details_dropdown
        with st.expander(f"–î–µ—Ç–∞–ª–∏ –ø–æ –ø–µ—Ä—Å–æ–Ω–µ: {person_to_show}", expanded=True):
            st.markdown(f"### –î–∏–Ω–∞–º–∏–∫–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –¥–ª—è: {person_to_show}")
            person_s_data = summary_data.get(person_to_show,{})
            if person_s_data:
                dates, pos_c, neg_c, neu_c = [],[],[],[]
                pos_label = tesa_labels.get(0, "POS"); neg_label = tesa_labels.get(1, "NEG"); neu_label = tesa_labels.get(2, "NEU")
                for date_str, counts in sorted(person_s_data.items()): 
                    try:
                        dates.append(pd.to_datetime(date_str).date()) 
                        pos_c.append(counts.get(pos_label,0)); neg_c.append(counts.get(neg_label,0)); neu_c.append(counts.get(neu_label,0))
                    except Exception as e_date_conv: 
                        print(f"UI WARNING: –û—à–∏–±–∫–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –¥–∞—Ç—ã '{date_str}' –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞ –ø–µ—Ä—Å–æ–Ω—ã '{person_to_show}': {e_date_conv}")
                        pass 
                if dates:
                    df_dyn = pd.DataFrame({'–î–∞—Ç–∞':dates, pos_label:pos_c, neg_label:neg_c, neu_label:neu_c}).set_index('–î–∞—Ç–∞')
                    st.line_chart(df_dyn, use_container_width=True)
                else: st.write("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–∞ –¥–∏–Ω–∞–º–∏–∫–∏.")
            else: st.write("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –¥–∏–Ω–∞–º–∏–∫–µ –¥–ª—è —ç—Ç–æ–π –ø–µ—Ä—Å–æ–Ω—ã.")            
            st.markdown(f"### –¢–µ–∫—Å—Ç—ã —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –¥–ª—è: {person_to_show}")
            p_mentions = [m for m in (detailed_mentions_data or []) if m.get("entity_normalized") == person_to_show]
            if p_mentions:
                max_texts_to_show_val = max(1, min(10, len(p_mentions))) 
                max_texts_slider_max = max(25, len(p_mentions))                
                max_texts = st.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤:", 
                                      min_value=1, 
                                      max_value=max_texts_slider_max, 
                                      value=max_texts_to_show_val, 
                                      key=f"txt_slider_{person_to_show.replace(' ','_')}_v5")                 
                for i,m in enumerate(p_mentions[:max_texts]):
                    st.markdown(f"**–£–ø–æ–º–∏–Ω–∞–Ω–∏–µ {i+1}**")
                    c1,c2,c3 = st.columns(3) 
                    with c1: st.caption(f"–¢–∏–ø: {m.get('source_type','N/A')}")
                    with c2: 
                        ts = m.get('timestamp')
                        date_str_display = "N/A"
                        if ts:
                            try: date_str_display = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M')
                            except: date_str_display = f"{ts} (–æ—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞)"
                        st.caption(f"–î–∞—Ç–∞: {date_str_display}")
                    with c3: st.caption(f"–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: {m.get('polarity','N/A')}")
                    st.markdown(f"> _{m.get('text_preview','–ù–µ—Ç —Ç–µ–∫—Å—Ç–∞')}_") 
                    st.markdown("---") 
            else: st.write("–ù–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –¥–ª—è —ç—Ç–æ–π –ø–µ—Ä—Å–æ–Ω—ã.")
            
# --- –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–æ—Ç–æ–∫–æ–º UI ---
st.set_page_config(page_title="–ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –ø–µ—Ä—Å–æ–Ω –≤ –í–ö", layout="wide", initial_sidebar_state="expanded")
st.title("üó£Ô∏è –ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –∫ –ø–µ—Ä—Å–æ–Ω–∞–º –≤ –≥—Ä—É–ø–ø–∞—Ö –í–ö–æ–Ω—Ç–∞–∫—Ç–µ")
st.markdown("–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –æ–±—ä–µ–∫—Ç–Ω–æ-–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–æ–≤ –∏–∑ –≥—Ä—É–ø–ø –í–ö–æ–Ω—Ç–∞–∫—Ç–µ.")
st.markdown("---")
if st.session_state.app_initialization_error:
    st.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: {st.session_state.app_initialization_error}")
    st.info("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –º–æ–¥–µ–ª–µ–π, –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º –∏ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –∫–æ–Ω—Å–æ–ª–∏.")
    st.stop() 
render_sidebar()
if st.session_state.analysis_triggered_and_pending:
    st.session_state.analysis_triggered_and_pending = False 
    group_identifier_to_process = st.session_state.last_processed_group_input
    service = st.session_state.analysis_service_instance 
    
    if st.session_state.last_processed_group_name != "–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞":
        st.header(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –≥—Ä—É–ø–ø—ã: {st.session_state.last_processed_group_name}")
        if st.session_state.last_processed_start_date and st.session_state.last_processed_end_date:
            st.subheader(f"–ü–µ—Ä–∏–æ–¥: {st.session_state.last_processed_start_date.strftime('%d.%m.%Y')} - {st.session_state.last_processed_end_date.strftime('%d.%m.%Y')}")
        st.markdown("---")
    
    if not service:
        st.error("–°–µ—Ä–≤–∏—Å –∞–Ω–∞–ª–∏–∑–∞ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω. –ó–∞–ø—É—Å–∫ –Ω–µ–≤–æ–∑–º–æ–∂–µ–Ω.")
    else:
        with st.spinner(f"–ò–¥–µ—Ç –∞–Ω–∞–ª–∏–∑ –≥—Ä—É–ø–ø—ã '{st.session_state.last_processed_group_name}' (ID/–¥–æ–º–µ–Ω: {group_identifier_to_process})... –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ."):
            try:
                analysis_results = asyncio.run(service.run_full_analysis(
                    group_identifiers_str=group_identifier_to_process,
                    date_start_str=st.session_state.last_processed_start_date.strftime("%Y-%m-%d"),
                    date_end_str=st.session_state.last_processed_end_date.strftime("%Y-%m-%d")
                ))
                if "error" in analysis_results: st.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {analysis_results['error']}")
                elif "message" in analysis_results and not analysis_results.get("summary"):
                    st.info(analysis_results['message'])
                    st.session_state.current_summary_display = {}; st.session_state.current_detailed_mentions_display = []
                    st.session_state.initial_summary = {}; st.session_state.initial_detailed_mentions = []
                elif analysis_results.get("summary") is not None:
                    summary_from_backend = analysis_results["summary"]
                    detailed_file = analysis_results.get("detailed_results_file")
                    mentions_from_file, _ = load_detailed_results_from_file(detailed_file) if detailed_file else ([], [])
                    st.session_state.initial_summary = copy.deepcopy(summary_from_backend)
                    st.session_state.initial_detailed_mentions = copy.deepcopy(mentions_from_file)
                    st.session_state.current_summary_display = copy.deepcopy(summary_from_backend)
                    st.session_state.current_detailed_mentions_display = copy.deepcopy(mentions_from_file)
                else: 
                    st.info("–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω. –ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è.")
                    st.session_state.current_summary_display = {}; st.session_state.current_detailed_mentions_display = []
                    st.session_state.initial_summary = {}; st.session_state.initial_detailed_mentions = []
                
                st.rerun() 

            except Exception as e_runtime: 
                st.error(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞: {e_runtime}")
                import traceback; st.text(traceback.format_exc())
                st.session_state.current_summary_display = None 
                st.session_state.initial_summary = None
                st.rerun() 
                
render_report_header()
            
if st.session_state.current_summary_display is not None:
    service_to_pass = st.session_state.analysis_service_instance 
    render_top10_summary(st.session_state.current_summary_display, st.session_state.tesa_id2label)    
    render_main_report_table_and_merge( 
        st.session_state.current_summary_display,
        st.session_state.current_detailed_mentions_display,
        st.session_state.tesa_id2label,
        service_to_pass )
    render_person_details_expander(
        st.session_state.current_summary_display,
        st.session_state.current_detailed_mentions_display,
        st.session_state.tesa_id2label)
elif not st.session_state.analysis_triggered_and_pending and st.session_state.app_initialization_error is None:
    st.info("–ó–∞–¥–∞–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∞–Ω–∞–ª–∏–∑–∞ –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏ –∏ –Ω–∞–∂–º–∏—Ç–µ '–ù–∞—á–∞—Ç—å –∞–Ω–∞–ª–∏–∑', —á—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.")
elif st.session_state.app_initialization_error:
    st.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: {st.session_state.app_initialization_error}")